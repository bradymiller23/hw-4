y = as.numeric(df$y),
method = 'glmnet',
trControl = controls,
tuneGrid = expand.grid(
alpha = 1,
lambda = 2^seq(-20, 0, by = 0.5)
),
family = 'gaussian'
)
covariate_matrix <- model.matrix(full_model)[, -1]
covariate_matrix
lasso_fit <- train(
x = full_model[,-1],
y = df$y,
method = 'glmnet',
trControl = controls,
tuneGrid = expand.grid(
alpha = 1,
lambda = 2^seq(-20, 0, by = 0.5)
),
family = 'gaussian'
)
full_model[,-1]
X <- torch_tensor(covariate_matrix, dtype = torch_float()) # Insert your code here
y <- torch_tensor(df$y, dtype = torch_float())
nn_linear()
?nn_linear()
logistic <- nn_module(
initialize = function() {
self$f <- nn_linear(6,1) # Insert your code here
self$g <- nn_sigmoid() # Insert your code here
},
forward = function(x) {
x %>%
self$f() %>%
self$g()
}
)
f <- logistic()
f
f(X)
Loss <- function(X, y, Fun){
y_pred <- Fun(X)
return(mean((y_pred - y)^2))
}
Loss(x_tensor, y_tensor, logistic_reg)
Loss(x_tensor, y_tensor, logistic)
f <- logistic()
optimizer <- optim_adam(logistic$parameters, lr=0.0001) # Insert your code here
n <- 1000
optimizer <- optim_adam(logistic$parameters, lr=0.0001) # Insert your code here
n <- 1000
loss <- L(x_tensor, y_tensor, logistic)
for (i in 1:epochs){
loss <- Loss(x_tensor, y_tensor, logistic)
optimizer$zero_grad()
loss$backward()
optimizer$step()
if (i %% 1000 == 0) {
cat(sprintf('Epoch: %d, Loss: %.6f\n', i, loss$item()))
}
}
for (i in 1:n){
loss <- Loss(x_tensor, y_tensor, logistic)
optimizer$zero_grad()
loss$backward()
optimizer$step()
if (i %% 1000 == 0) {
cat(sprintf('Epoch: %d, Loss: %.6f\n', i, loss$item()))
}
}
predicted_probabilities <- f(X) %>% as_array()
torch_predictions <- predict(predicted_probabilities)
renv::status()
renv::restore()
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"stringr",
"corrplot",
"car",
"caret",
"torch",
"nnet",
"broom"
)
renv::install(packages)
sapply(packages, require, character.only=T)
url <- "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"
df <- read.csv(url)
# changing column name of 'Survived'
colnames(df)[colnames(df) == 'Survived'] <- 'y'
# getting rid of . in the column names
colnames(df)[colnames(df) == 'Siblings.Spouses.Aboard'] <- 'Siblings Spouses Aboard'
colnames(df)[colnames(df) == 'Parents.Children.Aboard'] <- 'Parents Children Aboard'
# converting all the column names to lower case
colnames(df) <- tolower(colnames(df))
# changing the y (survived) and sex to factors
df$y <- as.factor(df$y)
df$sex <- as.factor(ifelse(df$sex == 'male', 1, 0))
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
library(dplyr)
install.packages('dplyr')
library(dplyr)
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
?select()
install.pacakages('tidyverse')
install.packages('tidyverse')
library(dplyr)
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"stringr",
"corrplot",
"car",
"caret",
"torch",
"nnet",
"broom"
)
renv::install(packages)
sapply(packages, require, character.only=T)
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"stringr",
"corrplot",
"car",
"caret",
"torch",
"nnet",
"broom"
)
renv::install(packages)
#sapply(packages, require, character.only=T)
library(dplyr)
renv::status()
renv::restore()
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"stringr",
"corrplot",
"car",
"caret",
"torch",
"nnet",
"broom"
)
renv::install(packages)
sapply(packages, require, character.only=T)
url <- "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"
df <- read.csv(url)
# changing column name of 'Survived'
colnames(df)[colnames(df) == 'Survived'] <- 'y'
# getting rid of . in the column names
colnames(df)[colnames(df) == 'Siblings.Spouses.Aboard'] <- 'Siblings Spouses Aboard'
colnames(df)[colnames(df) == 'Parents.Children.Aboard'] <- 'Parents Children Aboard'
# converting all the column names to lower case
colnames(df) <- tolower(colnames(df))
# changing the y (survived) and sex to factors
df$y <- as.factor(df$y)
df$sex <- as.factor(ifelse(df$sex == 'male', 1, 0))
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
# creating corrplot
corrplot(cor(dfCorr), method = 'color', tl.cex = 0.9, tl.col = 'black',
order = 'hclust')
full_model <-  glm(y ~ pclass + sex + age + `siblings spouses aboard` +
`parents children aboard` + fare, data = df,
family = binomial(link = 'logit'))
summary(full_model)
overview <- function(predicted, expected){
accuracy <- sum(expected == predicted) / length(expected)
error <- 1 - accuracy
total_false_positives <- sum(expected != predicted & expected == 0)
total_true_positives <- sum(expected == predicted & expected == 1)
total_false_negatives <- sum(expected != predicted & expected == 1)
total_true_negatives <- sum(expected == predicted & expected == 0)
false_positive_rate <- total_false_positives / (total_false_positives +
total_true_positives)
false_negative_rate <- total_false_negatives / (total_false_negatives +
total_true_negatives)
return(
data.frame(
accuracy = accuracy,
error=error,
false_positive_rate = false_positive_rate,
false_negative_rate = false_negative_rate
)
)
}
overview(df$y, df$y)
# getting predictions on the survival of Titanic passengers
predictions <- predict(full_model, newdata = df)
# getting expected value for survival (survived = 1, died = 0)
expected <- df$y
# using overview func we created to see key performance metrics of full_model
overview(predictions, expected)
# getting predictions on the survival of Titanic passengers
predictions <- predict(full_model)
predictions
full_model <-  glm(y ~ pclass + sex + age + `siblings spouses aboard` +
`parents children aboard` + fare, data = df,
family = binomial())
summary(full_model)
df <- df %>% mutate_at('y', factor)
str(df)
full_model <-  glm(y ~ pclass + sex + age + `siblings spouses aboard` +
`parents children aboard` + fare, data = df,
family = binomial())
summary(full_model)
renv::restore()
install.packages('rlang')
install.packages('vctrs')
install.packages('tibble')
install.packages('dplyr')
url <- "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"
df <- read.csv(url)
# changing column name of 'Survived'
colnames(df)[colnames(df) == 'Survived'] <- 'y'
# getting rid of . in the column names
colnames(df)[colnames(df) == 'Siblings.Spouses.Aboard'] <- 'Siblings Spouses Aboard'
colnames(df)[colnames(df) == 'Parents.Children.Aboard'] <- 'Parents Children Aboard'
# converting all the column names to lower case
colnames(df) <- tolower(colnames(df))
# changing the y (survived) and sex to factors
df$y <- as.factor(df$y)
df$sex <- as.factor(ifelse(df$sex == 'male', 1, 0))
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
renv::restore()
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
library(dplyr)
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"stringr",
"corrplot",
"car",
"caret",
"torch",
"nnet",
"broom"
)
renv::install(packages)
sapply(packages, require, character.only=T)
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
# creating corrplot
corrplot(cor(dfCorr), method = 'color', tl.cex = 0.9, tl.col = 'black',
order = 'hclust')
full_model <-  glm(y ~ pclass + sex + age + `siblings spouses aboard` +
`parents children aboard` + fare, data = df,
family = binomial())
summary(full_model)
sum(expected == predicted)
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"stringr",
"corrplot",
"car",
"caret",
"torch",
"nnet",
"broom"
)
renv::install(packages)
sapply(packages, require, character.only=T)
library(numDeriv)
g <- function(x) {
(x[1] - 3)^2 + (x[2] - 4)^2
}
grad(g, c(3,4))
######## FIX ME
f <- function(z){
(z^4) - 6*(z)^2 - 3*z + 4
}
z_tensor <- torch_tensor(-3.5, requires_grad = TRUE)
output_tensor <- f(z_tensor)
#_______$grad()
url <- "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"
df <- read.csv(url)
# changing column name of 'Survived'
colnames(df)[colnames(df) == 'Survived'] <- 'y'
# getting rid of . in the column names
colnames(df)[colnames(df) == 'Siblings.Spouses.Aboard'] <- 'Siblings Spouses Aboard'
colnames(df)[colnames(df) == 'Parents.Children.Aboard'] <- 'Parents Children Aboard'
# converting all the column names to lower case
colnames(df) <- tolower(colnames(df))
# changing the y (survived) and sex to factors
df$y <- as.factor(df$y)
df$sex <- as.factor(ifelse(df$sex == 'male', 1, 0))
# selecting only numeric variables
df %>%
select(-c(y, name, sex))
# creating corrplot
corrplot(cor(dfCorr), method = 'color', tl.cex = 0.9, tl.col = 'black',
order = 'hclust')
full_model <-  glm(y ~ pclass + sex + age + `siblings spouses aboard` +
`parents children aboard` + fare, data = df,
family = binomial())
summary(full_model)
overview <- function(predicted, expected){
accuracy <- sum(expected == predicted) / length(expected)
error <- 1 - accuracy
total_false_positives <- sum(expected != predicted & expected == 0)
total_true_positives <- sum(expected == predicted & expected == 1)
total_false_negatives <- sum(expected != predicted & expected == 1)
total_true_negatives <- sum(expected == predicted & expected == 0)
false_positive_rate <- total_false_positives / (total_false_positives +
total_true_positives)
false_negative_rate <- total_false_negatives / (total_false_negatives +
total_true_negatives)
return(
data.frame(
accuracy = accuracy,
error=error,
false_positive_rate = false_positive_rate,
false_negative_rate = false_negative_rate
)
)
}
overview(df$y, df$y)
# getting predictions on the survival of Titanic passengers
predictions <- predict(full_model)
# getting expected value for survival (survived = 1, died = 0)
expected <- df$y
# using overview func we created to see key performance metrics of full_model
overview(predictions, expected)
# creating null model which backwards stepwise logistic regression will end at
null_model <- glm(y ~ 1, df, family = binomial())
# creating the backwards stepwise logistic regression model
step_model <- step(full_model, direction = 'backward', scope = formula(null_model))
summary(step_model)
step_predictions <- predict(step_model, data = df)
overview(step_predictions, df$y)
controls <- trainControl(method = 'cv', number = 5)
controls
lasso_fit <- train(
x = df[,c(2,4,5,6,7)],
y = df$y,
method = 'glmnet',
trControl = controls,
tuneGrid = expand.grid(
alpha = 1,
lambda = 2^seq(-20, 0, by = 0.5)
),
family = 'gaussian'
)
lasso_fit <- train(
x = select(df, -name),
y = df$y,
method = 'glmnet',
trControl = controls,
tuneGrid = expand.grid(
alpha = 1,
lambda = 2^seq(-20, 0, by = 0.5)
),
family = 'gaussian'
)
lasso_fit <- train(
x = select(df, -y),
y = df$y,
method = 'glmnet',
trControl = controls,
tuneGrid = expand.grid(
alpha = 1,
lambda = 2^seq(-20, 0, by = 0.5)
),
family = 'gaussian'
)
lasso_fit <- train(
x = select(df, -y),
y = df$y,
method = 'glmnet',
trControl = controls,
tuneGrid = expand.grid(
alpha = 1,
lambda = 2^seq(-20, 0, by = 0.5)
),
standardize = TRUE
family = 'binomial'
lasso_fit <- train(
x = select(df, -y),
y = df$y,
method = 'glmnet',
trControl = controls,
tuneGrid = expand.grid(
alpha = 1,
lambda = 2^seq(-20, 0, by = 0.5)
),
standardize = TRUE,
family = 'binomial'
)
h <- function(u,v) {
sum(torch_matmul(u,v))^3
u <- torch_tensor(c(-1,1,-1,1,-1,1,-1,1,-1,1), requires_grad = TRUE)
v <- torch_tensor(c(1,-1,1,-1,1,-1,1,-1,1,-1))
}
gradient <- grad(h(u,v), u)
library(numDeriv)
h <- function(u,v) {
sum(torch_matmul(u,v))^3
u <- torch_tensor(c(-1,1,-1,1,-1,1,-1,1,-1,1), requires_grad = TRUE)
v <- torch_tensor(c(1,-1,1,-1,1,-1,1,-1,1,-1))
}
gradient <- grad(h(u,v), u)
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"stringr",
"corrplot",
"car",
"caret",
"torch",
"nnet",
"broom"
)
renv::install(packages)
sapply(packages, require, character.only=T)
library(numDeriv)
g <- function(x) {
(x[1] - 3)^2 + (x[2] - 4)^2
}
grad(g, c(3,4))
h <- function(u,v) {
sum(torch_matmul(u,v))^3
u <- torch_tensor(c(-1,1,-1,1,-1,1,-1,1,-1,1), requires_grad = TRUE)
v <- torch_tensor(c(1,-1,1,-1,1,-1,1,-1,1,-1))
}
grad(h(u,v), u)
sum(torch_matmul(u,v))^3
h <- function(u,v) {
sum(torch_matmul(u,v))^3
}
u <- torch_tensor(c(-1,1,-1,1,-1,1,-1,1,-1,1), requires_grad = TRUE)
v <- torch_tensor(c(1,-1,1,-1,1,-1,1,-1,1,-1))
grad(h(u,v), u)
?torch.dot()
h <- function(u,v){
(torch.dot(u,v))^3
}
u <- torch_tensor(c(-1,1,-1,1,-1,1,-1,1,-1,1), requires_grad = TRUE)
v <- torch_tensor(c(1,-1,1,-1,1,-1,1,-1,1,-1), requires_grad = TRUE)
output <- h(u,v)
h <- function(u,v){
(torch_dot(u,v))^3
}
u <- torch_tensor(c(-1,1,-1,1,-1,1,-1,1,-1,1), requires_grad = TRUE)
v <- torch_tensor(c(1,-1,1,-1,1,-1,1,-1,1,-1), requires_grad = TRUE)
output <- h(u,v)
output.backward()
h <- function(u,v){
(torch_dot(u,v))^3
}
u <- torch_tensor(c(-1,1,-1,1,-1,1,-1,1,-1,1), requires_grad = TRUE)
v <- torch_tensor(c(1,-1,1,-1,1,-1,1,-1,1,-1), requires_grad = TRUE)
output <- h(u,v)
output$backward()
u.grad
f <- function(z){
(z^4) - 6*(z)^2 - 3*z + 4
}
z_tensor <- torch_tensor(-3.5, requires_grad = TRUE)
output_tensor <- grad(f(z_tensor),z)
f <- function(z){
(z^4) - 6*(z)^2 - 3*z + 4
}
z_tensor <- torch_tensor(-3.5, requires_grad = TRUE)
output <- grad(f(z_tensor),z)
url <- "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"
df <- read.csv(url)
# changing column name of 'Survived'
colnames(df)[colnames(df) == 'Survived'] <- 'y'
# getting rid of . in the column names
colnames(df)[colnames(df) == 'Siblings.Spouses.Aboard'] <- 'Siblings Spouses Aboard'
colnames(df)[colnames(df) == 'Parents.Children.Aboard'] <- 'Parents Children Aboard'
# converting all the column names to lower case
colnames(df) <- tolower(colnames(df))
# changing the y (survived) and sex to factors
df$y <- as.factor(df$y)
df$sex <- as.factor(ifelse(df$sex == 'male', 1, 0))
View(df)
str(df)
